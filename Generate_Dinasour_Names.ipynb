{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baby Name Generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/david7joy/RNNProjects/blob/master/Generate_Dinasour_Names.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "RyPm7yoSJuDS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "874838fe-f3a7-46f1-b6da-23c2458201ef"
      },
      "cell_type": "code",
      "source": [
        "ls /content/drive/ColabNotebooks/ProjectRNN/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baby Name Generator.ipynb  babynames.txt  dinos.txt  \u001b[0m\u001b[01;34mlogs\u001b[0m/  setting drive.ipynb\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XpTwNes-MeSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68ac16c7-3d9d-4215-9177-1b39ebcb486e"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XP_OebJ6z9EL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "laR9qmZ9Mw6l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.contrib import rnn\n",
        "import random\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-fUC2DK3RMsV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logs_path = '/content/drive/ColabNotebooks/ProjectRNN/logs/'\n",
        "writer = tf.summary.FileWriter(logs_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vSENJIlfgNzP",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ae204b21-d413-4eab-c053-17347ff6af1a"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1851f45f-18a4-4341-b942-6ca06ee76bc4\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-1851f45f-18a4-4341-b942-6ca06ee76bc4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ZT1TY3t-sxom",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/ColabNotebooks/ProjectRNN/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HO78DnTss4Om",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf9a7a45-136c-4083-b3c4-1f5ab59a6ae8"
      },
      "cell_type": "code",
      "source": [
        "file = os.listdir()\n",
        "file = file[2]\n",
        "file"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dinos.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "metadata": {
        "id": "1BXFsaT_eRM_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(file) as f:\n",
        "    training_data = f.read()\n",
        "    training_data = training_data.replace('\\n',' ')\n",
        "    training_data = training_data.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lll6Y0zOx-DK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chars = list(set(training_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GGZyXGmgyBw4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10e34277-37f0-4deb-a66d-15fd3c799f53"
      },
      "cell_type": "code",
      "source": [
        "data_size,vocab_size = len(training_data),len(chars)\n",
        "print(\"The size of the data is %d and vocab size %d\"%(data_size,vocab_size))"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of the data is 19909 and vocab size 27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XD1zQ3E2yZCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "char_to_ix = {ch:i for i,ch in enumerate(sorted(chars))}\n",
        "ix_to_char = {i:ch for i,ch in enumerate(sorted(chars))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AdkAwztsydlQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# no of hidden cells or units in rnn\n",
        "n_hidden = 256\n",
        "\n",
        "# hyperparameters \n",
        "learning_rate = .001\n",
        "training_iters = 50000\n",
        "display_step = 2000\n",
        "time_steps = 7\n",
        "num_input = 1\n",
        "batch_size = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LU1F8TnfygB5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(\"float\",[batch_size,time_steps,num_input])  # the size of each input is 1*19\n",
        "y = tf.placeholder(\"float\",[batch_size,vocab_size])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jNdgMMq7zGUW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights = {'out':tf.Variable(tf.random_normal([n_hidden,vocab_size]))}\n",
        "biases = {'out':tf.Variable(tf.random_normal([vocab_size]))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p5X6WMl_zIeU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def RNN(x,weights,biases):\n",
        "    x = tf.reshape(x,[-1,time_steps])\n",
        "    x = tf.split(x,time_steps,1)\n",
        "    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])\n",
        "    rnn_cell = rnn.DropoutWrapper(rnn_cell, output_keep_prob=0.8)\n",
        "    #rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
        "    outputs,states = rnn.static_rnn(rnn_cell,x,dtype=tf.float32)\n",
        "    check1,check2 = outputs,states\n",
        "    return tf.matmul(outputs[-1],weights['out']) + biases['out']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fEun2X9vzMrS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = RNN(x,weights,biases)\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y))\n",
        "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
        "grads_and_vars = optimizer.compute_gradients(cost)\n",
        "capped_gvs = [(tf.clip_by_value(grad, -5, 5), var) for grad, var in grads_and_vars]\n",
        "training_op = optimizer.apply_gradients(capped_gvs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aAddceIazVDP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jTxwjn1wzZ86",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "outputId": "00ca9bc5-7a94-4a03-9919-5b6741e47a10"
      },
      "cell_type": "code",
      "source": [
        "#initializing the variable\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "start_time = time.time()\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    total_loss = 0\n",
        "    total_acc  = 0\n",
        "    offset = 0\n",
        "    r1 = offset\n",
        "    r2 = offset+(batch_size*time_steps)\n",
        "    \n",
        "    #saver = tf.train.Saver()\n",
        "    for steps in range(1, training_iters + 1):\n",
        "        if offset > 16200:\n",
        "            offset = 0\n",
        "            r1=offset\n",
        "            r2 = offset+(batch_size*time_steps)\n",
        "            \n",
        "\n",
        "        #getting the input sequence\n",
        "        #print(\"steps :%d offset1: %d range: %d\" %(steps,offset,batch_size*time_steps))\n",
        "        #print(r1,r2,steps)\n",
        "        X = [char_to_ix[str(training_data[i])] for i in range(r1, r2)]\n",
        "        X = np.reshape(np.array(X),[batch_size,time_steps,1])\n",
        "        batch_size = X.shape[0]\n",
        "        r1 = r2\n",
        "        r2 = r2+(batch_size*time_steps)\n",
        "\n",
        "        # getting ready the True Y\n",
        "        zeros_array = np.zeros((batch_size,vocab_size), dtype=float)\n",
        "        for i in range(batch_size):\n",
        "            zeros_array[i][char_to_ix[str(training_data[offset + time_steps])]] = 1.0\n",
        "            offset += time_steps\n",
        "            \n",
        "        Y = np.reshape(zeros_array, [batch_size, -1])\n",
        "        \n",
        "        #_, acc, cost,one_hot_pred = sess.run([optimizer, accuracy, cost, pred], feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
        "        _, acc, loss, onehot_pred = sess.run([training_op, accuracy, cost, pred], feed_dict={x: X, y: Y})\n",
        "        total_loss += loss\n",
        "        total_acc += acc\n",
        "        if steps % display_step == 0:\n",
        "            print(\"Iter= \" + str(steps+1) + \", Average Loss= \" + \"{:.6f}\".format(total_loss/display_step) + \", Average Accuracy= \" + \"{:.2f}%\".format((100*total_acc)/display_step))\n",
        "            total_loss = 0\n",
        "            total_acc = 0\n",
        "\n",
        "\n",
        "    # Save the variables to disk.\n",
        "    #save_path = saver.save(sess, \"/Users/davidjoy/Desktop/Github:Study Material/6341 - Applied Machine Learning/Rnn/Dinosaur Project\")\n",
        "    #print(\"Model saved in path: %s\" % save_path)\n",
        "    \n",
        "    #sampling\n",
        "    print(\"Total Mins {}\".format((time.time()-start_time)/60))\n",
        "    while True:\n",
        "      inputwords = \"enter 3 letters \" \n",
        "      enteredletters = input(inputwords)\n",
        "      letters = enteredletters.strip()\n",
        "      letters = list(letters)\n",
        "      if len(letters) != time_steps:\n",
        "            continue\n",
        "      try:\n",
        "        letters = [char_to_ix[i] for i in letters]\n",
        "        for i in range(50):\n",
        "          fixing_shape = np.zeros((batch_size,time_steps,1), dtype=float)\n",
        "          cell_input = np.reshape(np.array(letters), [-1, time_steps, 1])\n",
        "          cell_input = cell_input+fixing_shape\n",
        "          pred_letter = sess.run(pred,feed_dict={x:cell_input})\n",
        "          pred_letter = np.reshape(np.array(pred_letter[1]),(1,vocab_size))\n",
        "          pred_location = int(tf.argmax(pred_letter,axis=1).eval())\n",
        "          pred_location\n",
        "          enteredletters += \"%s\"%(ix_to_char[pred_location])\n",
        "          letters.append(pred_location)\n",
        "          letters = letters[1:]\n",
        "          name = enteredletters.split()[0]\n",
        "#         for i in names:\n",
        "        print(name)\n",
        "      except:\n",
        "        print(\"letter not in dictionary\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter= 2001, Average Loss= 1.132593, Average Accuracy= 65.18%\n",
            "Iter= 4001, Average Loss= 0.266838, Average Accuracy= 90.09%\n",
            "Iter= 6001, Average Loss= 0.236318, Average Accuracy= 90.96%\n",
            "Iter= 8001, Average Loss= 0.225620, Average Accuracy= 91.24%\n",
            "Iter= 10001, Average Loss= 0.219362, Average Accuracy= 91.40%\n",
            "Iter= 12001, Average Loss= 0.215926, Average Accuracy= 91.50%\n",
            "Iter= 14001, Average Loss= 0.213870, Average Accuracy= 91.57%\n",
            "Iter= 16001, Average Loss= 0.212035, Average Accuracy= 91.58%\n",
            "Iter= 18001, Average Loss= 0.210928, Average Accuracy= 91.62%\n",
            "Iter= 20001, Average Loss= 0.209886, Average Accuracy= 91.66%\n",
            "Iter= 22001, Average Loss= 0.209285, Average Accuracy= 91.67%\n",
            "Iter= 24001, Average Loss= 0.208734, Average Accuracy= 91.68%\n",
            "Iter= 26001, Average Loss= 0.208092, Average Accuracy= 91.68%\n",
            "Iter= 28001, Average Loss= 0.207792, Average Accuracy= 91.70%\n",
            "Iter= 30001, Average Loss= 0.207294, Average Accuracy= 91.72%\n",
            "Iter= 32001, Average Loss= 0.207011, Average Accuracy= 91.73%\n",
            "Iter= 34001, Average Loss= 0.207088, Average Accuracy= 91.71%\n",
            "Iter= 36001, Average Loss= 0.206712, Average Accuracy= 91.76%\n",
            "Iter= 38001, Average Loss= 0.206287, Average Accuracy= 91.78%\n",
            "Iter= 40001, Average Loss= 0.206156, Average Accuracy= 91.79%\n",
            "Iter= 42001, Average Loss= 0.205956, Average Accuracy= 91.77%\n",
            "Iter= 44001, Average Loss= 0.205715, Average Accuracy= 91.80%\n",
            "Iter= 46001, Average Loss= 0.205443, Average Accuracy= 91.79%\n",
            "Iter= 48001, Average Loss= 0.205358, Average Accuracy= 91.83%\n",
            "Iter= 50001, Average Loss= 0.205447, Average Accuracy= 91.84%\n",
            "Total Mins 19.6195769627889\n",
            "enter 3 letters bra\n",
            "enter 3 letters trx\n",
            "enter 3 letters bratrxe\n",
            "bratrxetr\n",
            "enter 3 letters bracusa\n",
            "bracusavrus\n",
            "enter 3 letters mangosr\n",
            "mangosrusosasrus\n",
            "enter 3 letters birgdet\n",
            "birgdets\n",
            "enter 3 letters aarsoaa\n",
            "aarsoaanacrssaurus\n",
            "enter 3 letters raptor\n",
            "enter 3 letters poribas\n",
            "poribasatiuaurus\n",
            "enter 3 letters jackret\n",
            "jackretodouaurus\n",
            "enter 3 letters buzingaa\n",
            "enter 3 letters doczero\n",
            "doczerotaurus\n",
            "enter 3 letters buzinga\n",
            "buzinga\n",
            "enter 3 letters marvelo\n",
            "marveloaurus\n",
            "enter 3 letters velopot\n",
            "velopotahosaurus\n",
            "enter 3 letters dectrio\n",
            "dectrioasrs\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}