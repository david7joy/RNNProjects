{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import random\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of total Chars is 19909 and size of unique is 27 \n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing and creating dictionary  \n",
    "\n",
    "training_data = open('dinos.txt','r').read().lower()\n",
    "chars = list(set(training_data))\n",
    "data_size,vocab_size = len(training_data),len(chars)\n",
    "print(\"The size of total Chars is %d and size of unique is %d \" %(data_size,vocab_size))\n",
    "char_to_ix = {ch:i for i,ch in enumerate(sorted(chars))}\n",
    "ix_to_char = {i:ch for i,ch in enumerate(sorted(chars))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the log for tensorboard\n",
    "logs_path = '/Users/davidjoy/Desktop/log'\n",
    "writer = tf.summary.FileWriter(logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of hidden cells or units in rnn\n",
    "n_hidden = 128\n",
    "\n",
    "# hyperparameters \n",
    "\n",
    "learning_rate = .001\n",
    "training_iters = 200000\n",
    "display_step = 5000\n",
    "time_steps = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\",[None,time_steps,1])\n",
    "Y = tf.placeholder(\"float\",[None,vocab_size])\n",
    "\n",
    "weights = {'out':tf.Variable(tf.random_normal([n_hidden,vocab_size]))}\n",
    "biases = {'out':tf.Variable(tf.random_normal([vocab_size]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the RNN block \n",
    "\n",
    "def RNN(x,weights,biases):\n",
    "    x = tf.reshape(x,[-1,time_steps])\n",
    "    x = tf.split(x,time_steps,1)\n",
    "    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])\n",
    "    outputs,states = rnn.static_rnn(rnn_cell,x,dtype=tf.float32)\n",
    "    return tf.matmul(outputs[-1],weights['out'])+biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor \n",
    "\n",
    "pred = RNN(x,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimization \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 5000, Average Loss= 2.599234, Average Accuracy= 22.94%\n",
      "['p', 'h', 'o'] - [l] vs [a]\n",
      "Iter= 10000, Average Loss= 2.340719, Average Accuracy= 32.78%\n",
      "['l', 'u', 's'] - [\n",
      "] vs [\n",
      "]\n",
      "Iter= 15000, Average Loss= 2.207374, Average Accuracy= 36.28%\n",
      "['\\n', 'a', 'e'] - [p] vs [o]\n",
      "Iter= 20000, Average Loss= 2.210960, Average Accuracy= 36.60%\n",
      "['i', 'l', 'i'] - [s] vs [o]\n",
      "Iter= 25000, Average Loss= 2.174942, Average Accuracy= 37.22%\n",
      "['g', 'e', 'n'] - [i] vs [o]\n",
      "Iter= 30000, Average Loss= 2.117689, Average Accuracy= 38.44%\n",
      "['l', 'b', 'e'] - [r] vs [r]\n",
      "Iter= 35000, Average Loss= 2.075203, Average Accuracy= 39.78%\n",
      "['e', 't', 'o'] - [p] vs [s]\n",
      "Iter= 40000, Average Loss= 2.032519, Average Accuracy= 40.48%\n",
      "['n', 'a', 'x'] - [\n",
      "] vs [o]\n",
      "Iter= 45000, Average Loss= 2.047342, Average Accuracy= 41.64%\n",
      "['m', 'o', 's'] - [a] vs [a]\n",
      "Iter= 50000, Average Loss= 2.007288, Average Accuracy= 41.60%\n",
      "['u', 'r', 'u'] - [s] vs [s]\n",
      "Iter= 55000, Average Loss= 1.950304, Average Accuracy= 43.68%\n",
      "['s', 'a', 'u'] - [r] vs [r]\n",
      "Iter= 60000, Average Loss= 1.946454, Average Accuracy= 44.36%\n",
      "['r', 'u', 's'] - [\n",
      "] vs [\n",
      "]\n",
      "Iter= 65000, Average Loss= 1.933317, Average Accuracy= 44.28%\n",
      "['t', 'a', '\\n'] - [a] vs [a]\n",
      "Iter= 70000, Average Loss= 1.878950, Average Accuracy= 45.56%\n",
      "['\\n', 'a', 'p'] - [a] vs [a]\n",
      "Iter= 75000, Average Loss= 1.862558, Average Accuracy= 45.62%\n",
      "['\\n', 'a', 'r'] - [c] vs [a]\n",
      "Iter= 80000, Average Loss= 1.881912, Average Accuracy= 45.52%\n",
      "['s', '\\n', 'a'] - [r] vs [r]\n",
      "Iter= 85000, Average Loss= 1.809254, Average Accuracy= 47.14%\n",
      "['a', 'r', 'i'] - [s] vs [a]\n",
      "Iter= 90000, Average Loss= 1.825762, Average Accuracy= 47.64%\n",
      "['s', 'i', 'a'] - [m] vs [\n",
      "]\n",
      "Iter= 95000, Average Loss= 1.816666, Average Accuracy= 47.12%\n",
      "['t', 'i', 't'] - [a] vs [a]\n",
      "Iter= 100000, Average Loss= 1.766126, Average Accuracy= 48.08%\n",
      "['a', 'u', 'r'] - [u] vs [u]\n",
      "Iter= 105000, Average Loss= 1.766312, Average Accuracy= 48.26%\n",
      "['i', 'r', 'u'] - [s] vs [s]\n",
      "Iter= 110000, Average Loss= 1.776058, Average Accuracy= 47.78%\n",
      "['i', 'm', 'i'] - [m] vs [a]\n",
      "Iter= 115000, Average Loss= 1.715907, Average Accuracy= 49.08%\n",
      "['c', 'e', 'r'] - [a] vs [a]\n",
      "Iter= 120000, Average Loss= 1.714723, Average Accuracy= 48.76%\n",
      "['m', '\\n', 'b'] - [a] vs [r]\n",
      "Iter= 125000, Average Loss= 1.669200, Average Accuracy= 50.36%\n",
      "['s', '\\n', 'b'] - [a] vs [a]\n",
      "Iter= 130000, Average Loss= 1.819391, Average Accuracy= 48.50%\n",
      "['n', 'l', 'o'] - [n] vs [s]\n",
      "Iter= 135000, Average Loss= 1.741065, Average Accuracy= 49.42%\n",
      "['l', 'b', 'e'] - [y] vs [r]\n",
      "Iter= 140000, Average Loss= 1.651960, Average Accuracy= 51.24%\n",
      "['\\n', 'b', 'o'] - [n] vs [a]\n",
      "Iter= 145000, Average Loss= 1.676375, Average Accuracy= 49.32%\n",
      "['o', 'r', 'o'] - [g] vs [i]\n",
      "Iter= 150000, Average Loss= 1.619500, Average Accuracy= 51.86%\n",
      "['r', 'a', 'c'] - [h] vs [h]\n",
      "Iter= 155000, Average Loss= 1.643544, Average Accuracy= 50.86%\n",
      "['s', '\\n', 'b'] - [r] vs [a]\n",
      "Iter= 160000, Average Loss= 1.718413, Average Accuracy= 50.68%\n",
      "['u', 'i', 't'] - [r] vs [a]\n",
      "Iter= 165000, Average Loss= 1.603129, Average Accuracy= 51.20%\n",
      "['l', 'a', 'm'] - [o] vs [o]\n",
      "Iter= 170000, Average Loss= 1.631221, Average Accuracy= 52.34%\n",
      "['a', '\\n', 'c'] - [a] vs [a]\n",
      "Iter= 175000, Average Loss= 1.670972, Average Accuracy= 51.70%\n",
      "['o', 'd', 'o'] - [n] vs [n]\n",
      "Iter= 180000, Average Loss= 1.608220, Average Accuracy= 51.82%\n",
      "['o', 'e', 'l'] - [u] vs [o]\n",
      "Iter= 185000, Average Loss= 1.582543, Average Accuracy= 52.82%\n",
      "['s', '\\n', 'c'] - [e] vs [a]\n",
      "Iter= 190000, Average Loss= 1.534327, Average Accuracy= 52.78%\n",
      "['r', '\\n', 'c'] - [h] vs [a]\n",
      "Iter= 195000, Average Loss= 1.642694, Average Accuracy= 51.54%\n",
      "['u', 'r', 'u'] - [s] vs [s]\n",
      "Iter= 200000, Average Loss= 1.692562, Average Accuracy= 50.14%\n",
      "['s', 'a', 'u'] - [r] vs [r]\n",
      "Optimization Finished!\n",
      "Run on command line.\n",
      "\ttensorboard --logdir=/Users/davidjoy/Desktop/log\n",
      "Point your web browser to: http://localhost:6006/\n",
      "3 words: s a u \n",
      "s a urus\n",
      "chaeosaurus\n",
      "chaeosaurus\n",
      "chae\n",
      "3 words: p r t\n",
      "p r ts\n",
      "chaeosaurus\n",
      "chaeosaurus\n",
      "chaeos\n",
      "3 words: a r z\n",
      "a r zchus\n",
      "chaeosaurus\n",
      "chaeosaurus\n",
      "cha\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    step = 0\n",
    "    offset = random.randint(0,time_steps+1)\n",
    "    end_offset = time_steps + 1\n",
    "    acc_total = 0\n",
    "    loss_total = 0\n",
    "    \n",
    "    writer.add_graph(session.graph)\n",
    "\n",
    "    while step < training_iters:\n",
    "        # Generate a minibatch. Add some randomness on selection process.\n",
    "        if offset > (len(training_data)-end_offset):\n",
    "            offset = random.randint(0, time_steps+1)\n",
    "\n",
    "        symbols_in_keys = [ [char_to_ix[ str(training_data[i])]] for i in range(offset, offset+time_steps) ]\n",
    "        symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, time_steps, 1])\n",
    "\n",
    "        symbols_out_onehot = np.zeros([vocab_size], dtype=float)\n",
    "        symbols_out_onehot[char_to_ix[str(training_data[offset+time_steps])]] = 1.0\n",
    "        symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n",
    "\n",
    "        _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \\\n",
    "                                                feed_dict={x: symbols_in_keys, Y: symbols_out_onehot})\n",
    "        loss_total += loss\n",
    "        acc_total += acc\n",
    "        if (step+1) % display_step == 0:\n",
    "            print(\"Iter= \" + str(step+1) + \", Average Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss_total/display_step) + \", Average Accuracy= \" + \\\n",
    "                  \"{:.2f}%\".format(100*acc_total/display_step))\n",
    "            acc_total = 0\n",
    "            loss_total = 0\n",
    "            symbols_in = [training_data[i] for i in range(offset, offset + time_steps)]\n",
    "            symbols_out = training_data[offset + time_steps]\n",
    "            symbols_out_pred = ix_to_char[int(tf.argmax(onehot_pred, 1).eval())]\n",
    "            print(\"%s - [%s] vs [%s]\" % (symbols_in,symbols_out,symbols_out_pred))\n",
    "        step += 1\n",
    "        offset += (time_steps+1)\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Run on command line.\")\n",
    "    print(\"\\ttensorboard --logdir=%s\" % (logs_path))\n",
    "    print(\"Point your web browser to: http://localhost:6006/\")\n",
    "    while True:\n",
    "        prompt = \"%s words: \" % time_steps\n",
    "        sentence = input(prompt)\n",
    "        sentence = sentence.strip()\n",
    "        words = sentence.split(' ')\n",
    "        if len(words) != time_steps:\n",
    "            continue\n",
    "        try:\n",
    "            symbols_in_keys = [char_to_ix[str(words[i])] for i in range(len(words))]\n",
    "            for i in range(32):\n",
    "                keys = np.reshape(np.array(symbols_in_keys), [-1, time_steps, 1])\n",
    "                onehot_pred = session.run(pred, feed_dict={x: keys})\n",
    "                onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval())\n",
    "                sentence = \"%s%s\" % (sentence,ix_to_char[onehot_pred_index])\n",
    "                symbols_in_keys = symbols_in_keys[1:]\n",
    "                symbols_in_keys.append(onehot_pred_index)\n",
    "            print(sentence)\n",
    "        except:\n",
    "            print(\"Word not in dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
