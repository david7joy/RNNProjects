{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baby Name Generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/david7joy/RNNProjects/blob/master/Baby_Name_Generator.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "RyPm7yoSJuDS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e45ef229-452b-42d6-b3d6-2311d72e6dc7"
      },
      "cell_type": "code",
      "source": [
        "ls /content/drive/ColabNotebooks/ProjectRNN/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baby Name Generator.ipynb  babynames.txt  dinos.txt  \u001b[0m\u001b[01;34mlogs\u001b[0m/  setting drive.ipynb\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XpTwNes-MeSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9fb588a-f505-4ae3-f00e-f9604240f2fc"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XP_OebJ6z9EL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "laR9qmZ9Mw6l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.contrib import rnn\n",
        "import random\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-fUC2DK3RMsV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logs_path = '/content/drive/ColabNotebooks/ProjectRNN/logs/'\n",
        "writer = tf.summary.FileWriter(logs_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vSENJIlfgNzP",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a0d7828-a630-4bc1-8ce4-9afbcddf7395"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-683eba1e-8f9e-4054-9daa-8a28887a86f0\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-683eba1e-8f9e-4054-9daa-8a28887a86f0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "RfpN0sHfqx1R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84decdef-611f-40b7-f225-461630125083"
      },
      "cell_type": "code",
      "source": [
        "ls /drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/drive': No such file or directory\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZT1TY3t-sxom",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/ColabNotebooks/ProjectRNN/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HO78DnTss4Om",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73930e50-8dd0-43b5-8527-8bfee9874d06"
      },
      "cell_type": "code",
      "source": [
        "file = os.listdir()\n",
        "file = file[2]\n",
        "file"
      ],
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dinos.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 359
        }
      ]
    },
    {
      "metadata": {
        "id": "1BXFsaT_eRM_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(file) as f:\n",
        "    training_data = f.read()\n",
        "    training_data = training_data.replace('\\n',' ')\n",
        "    training_data = training_data.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lll6Y0zOx-DK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chars = list(set(training_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GGZyXGmgyBw4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "849cec61-0df9-42d3-9649-db14167dc389"
      },
      "cell_type": "code",
      "source": [
        "data_size,vocab_size = len(training_data),len(chars)\n",
        "print(\"The size of the data is %d and vocab size %d\"%(data_size,vocab_size))"
      ],
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of the data is 19909 and vocab size 27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XD1zQ3E2yZCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "char_to_ix = {ch:i for i,ch in enumerate(sorted(chars))}\n",
        "ix_to_char = {i:ch for i,ch in enumerate(sorted(chars))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AdkAwztsydlQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# no of hidden cells or units in rnn\n",
        "n_hidden = 128\n",
        "\n",
        "# hyperparameters \n",
        "learning_rate = .0005\n",
        "training_iters = 150000\n",
        "display_step = 1000\n",
        "time_steps = 3\n",
        "num_input = 1\n",
        "batch_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LU1F8TnfygB5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(\"float\",[batch_size,time_steps,num_input])  # the size of each input is 1*19\n",
        "y = tf.placeholder(\"float\",[batch_size,vocab_size])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jNdgMMq7zGUW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights = {'out':tf.Variable(tf.random_normal([n_hidden,vocab_size]))}\n",
        "biases = {'out':tf.Variable(tf.random_normal([vocab_size]))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p5X6WMl_zIeU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def RNN(x,weights,biases):\n",
        "    x = tf.reshape(x,[-1,time_steps])\n",
        "    x = tf.split(x,time_steps,1)\n",
        "    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])\n",
        "    #rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
        "    outputs,states = rnn.static_rnn(rnn_cell,x,dtype=tf.float32)\n",
        "    check1,check2 = outputs,states\n",
        "    return tf.matmul(outputs[-1],weights['out']) + biases['out']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fEun2X9vzMrS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = RNN(x,weights,biases)\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y))\n",
        "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
        "grads_and_vars = optimizer.compute_gradients(cost)\n",
        "capped_gvs = [(tf.clip_by_value(grad, -2, 2), var) for grad, var in grads_and_vars]\n",
        "training_op = optimizer.apply_gradients(capped_gvs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aAddceIazVDP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jTxwjn1wzZ86",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4023
        },
        "outputId": "c705414b-1255-4119-b0d6-88dfaa884b4b"
      },
      "cell_type": "code",
      "source": [
        "#initializing the variable\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "start_time = time.time()\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    total_loss = 0\n",
        "    total_acc  = 0\n",
        "    offset = 0\n",
        "    r1 = offset\n",
        "    r2 = offset+(batch_size*time_steps)\n",
        "    \n",
        "    #saver = tf.train.Saver()\n",
        "    for steps in range(1, training_iters + 1):\n",
        "        if offset > 16200:\n",
        "            offset = 0\n",
        "            r1=offset\n",
        "            r2 = offset+(batch_size*time_steps)\n",
        "            \n",
        "\n",
        "        #getting the input sequence\n",
        "        #print(\"steps :%d offset1: %d range: %d\" %(steps,offset,batch_size*time_steps))\n",
        "        #print(r1,r2,steps)\n",
        "        X = [char_to_ix[str(training_data[i])] for i in range(r1, r2)]\n",
        "        X = np.reshape(np.array(X),[batch_size,time_steps,1])\n",
        "        batch_size = X.shape[0]\n",
        "        r1 = r2\n",
        "        r2 = r2+(batch_size*time_steps)\n",
        "\n",
        "        # getting ready the True Y\n",
        "        zeros_array = np.zeros((batch_size,vocab_size), dtype=float)\n",
        "        for i in range(batch_size):\n",
        "            zeros_array[i][char_to_ix[str(training_data[offset + time_steps])]] = 1.0\n",
        "            offset += time_steps\n",
        "            \n",
        "        Y = np.reshape(zeros_array, [batch_size, -1])\n",
        "        \n",
        "        #_, acc, cost,one_hot_pred = sess.run([optimizer, accuracy, cost, pred], feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
        "        _, acc, loss, onehot_pred = sess.run([training_op, accuracy, cost, pred], feed_dict={x: X, y: Y})\n",
        "        total_loss += loss\n",
        "        total_acc += acc\n",
        "        if steps % display_step == 0:\n",
        "            print(steps,(100*total_acc)/steps,total_loss/steps)\n",
        "            \n",
        "\n",
        "    # Save the variables to disk.\n",
        "    #save_path = saver.save(sess, \"/Users/davidjoy/Desktop/Github:Study Material/6341 - Applied Machine Learning/Rnn/Dinosaur Project\")\n",
        "    #print(\"Model saved in path: %s\" % save_path)\n",
        "    \n",
        "    #sampling\n",
        "    print(\"Total Mins {}\".format((time.time()-start_time)/60))\n",
        "    while True:\n",
        "      inputwords = \"enter 3 letters \" \n",
        "      enteredletters = input(inputwords)\n",
        "      letters = enteredletters.strip()\n",
        "      letters = list(letters)\n",
        "      if len(letters) != time_steps:\n",
        "            continue\n",
        "      try:\n",
        "        letters = [char_to_ix[i] for i in letters]\n",
        "        for i in range(10):\n",
        "          fixing_shape = np.zeros((batch_size,3,1), dtype=float)\n",
        "          cell_input = np.reshape(np.array(letters), [-1, time_steps, 1])\n",
        "          cell_input = cell_input+fixing_shape\n",
        "          pred_letter = sess.run(pred,feed_dict={x:cell_input})\n",
        "          pred_letter = np.reshape(np.array(pred_letter[1]),(1,vocab_size))\n",
        "          pred_location = int(tf.argmax(pred_letter,axis=1).eval())\n",
        "          pred_location\n",
        "          enteredletters += \"%s\"%(ix_to_char[pred_location])\n",
        "          letters.append(pred_location)\n",
        "          letters = letters[1:]\n",
        "          names = enteredletters.split()\n",
        "          for i in names:\n",
        "            print(i)\n",
        "      except:\n",
        "        print(\"letter not in dictionary\")"
      ],
      "execution_count": 395,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 33.49921875 2.235990055322647\n",
            "2000 44.0046875 1.8079196329712868\n",
            "3000 50.21536458333333 1.5633492973645529\n",
            "4000 54.17578125 1.4131377943605186\n",
            "5000 56.8325 1.314915013563633\n",
            "6000 58.86080729166667 1.239735170563062\n",
            "7000 60.36305803571429 1.184519168147019\n",
            "8000 61.57177734375 1.140108802817762\n",
            "9000 62.571354166666666 1.1030431514845953\n",
            "10000 63.38546875 1.0727496922343969\n",
            "11000 64.06569602272727 1.0477741292091933\n",
            "12000 64.43776041666666 1.0330513514305155\n",
            "13000 64.8578125 1.0163571087970182\n",
            "14000 65.32745535714285 0.998990242251328\n",
            "15000 65.76520833333333 0.9828368821044763\n",
            "16000 66.153173828125 0.9688453332539648\n",
            "17000 66.53005514705882 0.9553194113549064\n",
            "18000 66.82391493055556 0.9445675472799274\n",
            "19000 67.03782894736842 0.9365434409474072\n",
            "20000 67.2756640625 0.9279617691472173\n",
            "21000 67.50513392857142 0.9195682346324126\n",
            "22000 67.73224431818181 0.9116462865133177\n",
            "23000 67.8976222826087 0.9056232815397822\n",
            "24000 68.08600260416667 0.8992147284336388\n",
            "25000 68.2046875 0.8950413888800144\n",
            "26000 68.24068509615384 0.893669117973401\n",
            "27000 68.23423032407408 0.8933016239537133\n",
            "28000 68.16824776785714 0.8948069168946573\n",
            "29000 68.13173491379311 0.8950946544347138\n",
            "30000 68.17046875 0.8930909698069096\n",
            "31000 68.24322076612903 0.8904027754010693\n",
            "32000 68.3342529296875 0.8868403863869607\n",
            "33000 68.42549715909091 0.8835246461503433\n",
            "34000 68.49427849264706 0.8810746181957861\n",
            "35000 68.53388392857143 0.8794669195660523\n",
            "36000 68.567578125 0.878038292594254\n",
            "37000 68.62238175675675 0.8760227794035061\n",
            "38000 68.672265625 0.8740916500530744\n",
            "39000 68.69282852564102 0.8732623423689451\n",
            "40000 68.7065625 0.8727093446999789\n",
            "41000 68.77614329268293 0.8704138819735224\n",
            "42000 68.85310639880953 0.8680198601491395\n",
            "43000 68.9157340116279 0.8660264246893483\n",
            "44000 68.93371803977273 0.865649103643542\n",
            "45000 68.95201388888889 0.864986513149076\n",
            "46000 68.97287703804348 0.8643281333900016\n",
            "47000 68.99682513297873 0.8638066688281425\n",
            "48000 69.00094401041666 0.8640012404217075\n",
            "49000 68.98502869897959 0.8646813500189051\n",
            "50000 69.0034375 0.8640856085693837\n",
            "51000 69.03203125 0.8631050165763088\n",
            "52000 69.04932391826924 0.8626384442379842\n",
            "53000 69.05517393867925 0.8624121325814499\n",
            "54000 69.04762731481482 0.8627007009409092\n",
            "55000 69.06823863636363 0.8618005537033081\n",
            "56000 69.08678850446428 0.8611932968066207\n",
            "57000 69.08913103070175 0.8610792280989781\n",
            "58000 69.09213362068965 0.8610640396809783\n",
            "59000 69.10734904661017 0.8606788784462517\n",
            "60000 69.09462239583333 0.8614807351008058\n",
            "61000 69.06695696721312 0.8627520488202571\n",
            "62000 69.06110131048388 0.8629099397332437\n",
            "63000 69.06360367063492 0.8627756182229708\n",
            "64000 69.0701171875 0.8626202981229871\n",
            "65000 69.08961538461539 0.861958887793926\n",
            "66000 69.10912642045454 0.8613524050279097\n",
            "67000 69.1329640858209 0.8606354485118567\n",
            "68000 69.15050551470588 0.8603081158399581\n",
            "69000 69.1745357789855 0.859674650574076\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "70000 69.19291294642858 0.8594771341924157\n",
            "71000 69.21465669014084 0.85909782306787\n",
            "72000 69.2266818576389 0.8591195967598921\n",
            "73000 69.22144691780822 0.8599572996003171\n",
            "74000 69.20935388513513 0.860764743396962\n",
            "75000 69.180125 0.8621405942006906\n",
            "76000 69.13942228618421 0.8637790140372358\n",
            "77000 69.08564326298702 0.8656536698918064\n",
            "78000 69.0412860576923 0.8670486147705561\n",
            "79000 69.00471716772152 0.8681801304307919\n",
            "80000 68.972314453125 0.8694064283449203\n",
            "81000 68.94155092592592 0.8705383106915303\n",
            "82000 68.91983612804879 0.8714967506869538\n",
            "83000 68.90106362951808 0.8721558928223978\n",
            "84000 68.88148251488096 0.8729100232734567\n",
            "85000 68.87409007352942 0.8731203264643165\n",
            "86000 68.87370094476744 0.8732695244176443\n",
            "87000 68.87078843390805 0.8735934688359841\n",
            "88000 68.86490589488636 0.874080075792291\n",
            "89000 68.84212605337079 0.8754074052324455\n",
            "90000 68.812734375 0.8768718375954363\n",
            "91000 68.77953296703296 0.8784924454453227\n",
            "92000 68.74821671195652 0.8799624407058176\n",
            "93000 68.71909442204301 0.8815671462730695\n",
            "94000 68.70269281914894 0.8825692183882632\n",
            "95000 68.68333059210526 0.883677564102725\n",
            "96000 68.6593017578125 0.8852043959908188\n",
            "97000 68.64071359536082 0.8865174732865746\n",
            "98000 68.62541454081632 0.8875752744592574\n",
            "99000 68.59884785353535 0.8891770429746672\n",
            "100000 68.5759375 0.8906325510898232\n",
            "101000 68.56697091584158 0.8912108996879347\n",
            "102000 68.54595588235294 0.8924896696236204\n",
            "103000 68.52687348300971 0.893719230386528\n",
            "104000 68.50686598557692 0.8949495327658952\n",
            "105000 68.47659226190476 0.8967232444641136\n",
            "106000 68.44150943396227 0.8987385058552027\n",
            "107000 68.39960572429906 0.9009065595739912\n",
            "108000 68.36001157407408 0.902720475209256\n",
            "109000 68.32651949541284 0.9042619609091807\n",
            "110000 68.29092329545455 0.9060063251145861\n",
            "111000 68.25541948198199 0.9076198565796152\n",
            "112000 68.22920619419642 0.9087845648104059\n",
            "113000 68.20464601769912 0.9099156216913092\n",
            "114000 68.17499314692982 0.9114263839055049\n",
            "115000 68.14541440217391 0.9128468397464441\n",
            "116000 68.11257408405173 0.9141915748712831\n",
            "117000 68.08828125 0.9151258589556583\n",
            "118000 68.06793564618644 0.9160916359906984\n",
            "119000 68.03838629201681 0.9176931404123286\n",
            "120000 68.01165364583333 0.9190312401148181\n",
            "121000 67.98609245867769 0.920165072481248\n",
            "122000 67.9564613217213 0.9215401232098458\n",
            "123000 67.92147484756097 0.9231060202497292\n",
            "124000 67.89175277217743 0.9244592085137002\n",
            "125000 67.865175 0.9254774054291248\n",
            "126000 67.84376240079365 0.9263462314437779\n",
            "127000 67.82157357283465 0.9273120021451646\n",
            "128000 67.80296020507812 0.9283363553702365\n",
            "129000 67.78175266472869 0.929595084112975\n",
            "130000 67.75982572115385 0.930785307209079\n",
            "131000 67.74131083015267 0.9319221892504747\n",
            "132000 67.72326586174242 0.9332082486827716\n",
            "133000 67.70939262218045 0.9342033677246786\n",
            "134000 67.70001749067164 0.9350773427706601\n",
            "135000 67.68556134259259 0.9364437412661535\n",
            "136000 67.67241498161765 0.9374906835282112\n",
            "137000 67.65902714416059 0.9386081512141837\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "138000 67.641015625 0.9401799836122039\n",
            "139000 67.62533723021583 0.9414602291796276\n",
            "140000 67.61048549107143 0.9427052484782679\n",
            "141000 67.59775044326241 0.9438822722517429\n",
            "142000 67.57944542253522 0.9456738625468922\n",
            "143000 67.55907998251749 0.9476443078607529\n",
            "144000 67.53181423611112 0.9499333381212006\n",
            "145000 67.50592672413794 0.9517700063921254\n",
            "146000 67.48322452910959 0.9533570029749854\n",
            "147000 67.45948129251701 0.9550728307433274\n",
            "148000 67.4406566722973 0.9564156125499993\n",
            "149000 67.4196990352349 0.9579570326527093\n",
            "150000 67.39704166666667 0.959582185506622\n",
            "Total Mins 21.767718601226807\n",
            "enter 3 letters rop\n",
            "rope\n",
            "ropel\n",
            "ropelt\n",
            "ropelts\n",
            "ropelts\n",
            "ropelts\n",
            "s\n",
            "ropelts\n",
            "sa\n",
            "ropelts\n",
            "sau\n",
            "ropelts\n",
            "saur\n",
            "ropelts\n",
            "sauru\n",
            "enter 3 letters tro\n",
            "tros\n",
            "trosa\n",
            "trosau\n",
            "trosaur\n",
            "trosauru\n",
            "trosaurus\n",
            "trosaurus\n",
            "trosaurus\n",
            "c\n",
            "trosaurus\n",
            "ch\n",
            "trosaurus\n",
            "chi\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \"\"\"\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-395-03b36ef32977>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0minputwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"enter 3 letters \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0menteredletters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m       \u001b[0mletters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menteredletters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0mletters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}